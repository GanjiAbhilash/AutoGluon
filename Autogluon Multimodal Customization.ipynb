{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11c3fa6c",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"../utils/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4339d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #install AutoGluon\n",
    "# !pip install -q autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269dc45e",
   "metadata": {},
   "source": [
    "# Customize AutoMM\n",
    "\n",
    "\n",
    "\n",
    "AutoMM has a powerful yet easy-to-use configuration design.\n",
    "This tutorial walks you through various AutoMM configurations to empower you the customization flexibility. Specifically, AutoMM configurations consist of four parts:\n",
    "\n",
    "- optimization\n",
    "- environment\n",
    "- model\n",
    "- data\n",
    "\n",
    "## Optimization\n",
    "\n",
    "### optimization.learning_rate\n",
    "Learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d5ebb3",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.learning_rate\": 1.0e-4})\n",
    "# set learning rate to 5.0e-4\n",
    "predictor.fit(hyperparameters={\"optimization.learning_rate\": 5.0e-4})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f53ae",
   "metadata": {},
   "source": [
    "### optimization.optim_type\n",
    "Optimizer type.\n",
    "\n",
    "- `\"sgd\"`: stochastic gradient descent with momentum.\n",
    "- `\"adam\"`: a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments. See [this paper](https://arxiv.org/abs/1412.6980) for details.\n",
    "- `\"adamw\"`: improves adam by decoupling the weight decay from the optimization step. See [this paper](https://arxiv.org/abs/1711.05101) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef9d29",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.optim_type\": \"adamw\"})\n",
    "# use optimizer adam\n",
    "predictor.fit(hyperparameters={\"optimization.optim_type\": \"adam\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d1338",
   "metadata": {},
   "source": [
    "### optimization.weight_decay\n",
    "Weight decay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b558c9",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.weight_decay\": 1.0e-3})\n",
    "# set weight decay to 1.0e-4\n",
    "predictor.fit(hyperparameters={\"optimization.weight_decay\": 1.0e-4})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9421419b",
   "metadata": {},
   "source": [
    "### optimization.lr_decay\n",
    "Later layers can have larger learning rates than the earlier layers. The last/head layer\n",
    "has the largest learning rate `optimization.learning_rate`. For a model with `n` layers, layer `i` has learning rate `optimization.learning_rate * optimization.lr_decay^(n-i)`. To use one uniform learning rate, simply set the learning rate decay to `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de59d79",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.lr_decay\": 0.9})\n",
    "# turn off learning rate decay\n",
    "predictor.fit(hyperparameters={\"optimization.lr_decay\": 1})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9f4db",
   "metadata": {},
   "source": [
    "### optimization.lr_schedule\n",
    "Learning rate schedule.\n",
    "\n",
    "- `\"cosine_decay\"`: the decay of learning rate follows the cosine curve.\n",
    "- `\"polynomial_decay\"`: the learning rate is decayed based on polynomial functions. \n",
    "- `\"linear_decay\"`: linearly decays the learing rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4846a3",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.lr_schedule\": \"cosine_decay\"})\n",
    "# use polynomial decay\n",
    "predictor.fit(hyperparameters={\"optimization.lr_schedule\": \"polynomial_decay\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28e7758",
   "metadata": {},
   "source": [
    "### optimization.max_epochs\n",
    "Stop training once this number of epochs is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13091422",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.max_epochs\": 10})\n",
    "# train 20 epochs\n",
    "predictor.fit(hyperparameters={\"optimization.max_epochs\": 20})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a4d29",
   "metadata": {},
   "source": [
    "### optimization.max_steps\n",
    "Stop training after this number of steps. Training will stop if `optimization.max_steps` or `optimization.max_epochs` have reached (earliest).\n",
    "By default, we disable `optimization.max_steps` by setting it to -1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c671bc08",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.max_steps\": -1})\n",
    "# train 100 steps\n",
    "predictor.fit(hyperparameters={\"optimization.max_steps\": 100})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc135e6d",
   "metadata": {},
   "source": [
    "### optimization.warmup_steps\n",
    "Warm up the learning rate from 0 to `optimization.learning_rate` within this percentage of steps at the beginning of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05e551c",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.warmup_steps\": 0.1})\n",
    "# do learning rate warmup in the first 20% steps.\n",
    "predictor.fit(hyperparameters={\"optimization.warmup_steps\": 0.2})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d67e02f",
   "metadata": {},
   "source": [
    "### optimization.patience\n",
    "Stop training after this number of checks with no improvement. The check frequency is controlled by `optimization.val_check_interval`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34919d37",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.patience\": 10})\n",
    "# set patience to 5 checks\n",
    "predictor.fit(hyperparameters={\"optimization.patience\": 5})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ceda5c",
   "metadata": {},
   "source": [
    "### optimization.val_check_interval\n",
    "How often within one training epoch to check the validation set. Can specify as float or int.\n",
    "\n",
    "- pass a float in the range [0.0, 1.0] to check after a fraction of the training epoch.\n",
    "- pass an int to check after a fixed number of training batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef91f723",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.val_check_interval\": 0.5})\n",
    "# check validation set 4 times during a training epoch\n",
    "predictor.fit(hyperparameters={\"optimization.val_check_interval\": 0.25})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40316434",
   "metadata": {},
   "source": [
    "### optimization.top_k\n",
    "Based on the validation score, choose top k model checkpoints to do model averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef4fd4f",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.top_k\": 3})\n",
    "# use top 5 checkpoints\n",
    "predictor.fit(hyperparameters={\"optimization.top_k\": 5})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ed16f",
   "metadata": {},
   "source": [
    "### optimization.top_k_average_method\n",
    "Use what strategy to average the top k model checkpoints.\n",
    "\n",
    "- `\"greedy_soup\"`: tries to add the checkpoints from best to worst into the averaging pool and stop if the averaged checkpoint performance decreases. See [the paper](https://arxiv.org/pdf/2203.05482.pdf) for details.\n",
    "- `\"uniform_soup\"`: averages all the top k checkpoints as the final checkpoint.\n",
    "- `\"best\"`: picks the checkpoint with the best validation performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1257b",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.top_k_average_method\": \"greedy_soup\"})\n",
    "# average all the top k checkpoints\n",
    "predictor.fit(hyperparameters={\"optimization.top_k_average_method\": \"uniform_soup\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34507e79",
   "metadata": {},
   "source": [
    "### optimization.efficient_finetune\n",
    "Finetune only a small portion of parameters instead of one whole pretrained backbone.\n",
    "\n",
    "- `\"bit_fit\"`: bias parameters only. See [this paper](https://arxiv.org/pdf/2106.10199.pdf) for details.\n",
    "- `\"norm_fit\"`: normalization parameters + bias parameters. See [this paper](https://arxiv.org/pdf/2003.00152.pdf) for details.\n",
    "- `\"lora\"`: LoRA Adaptors. See [this paper](https://arxiv.org/pdf/2106.09685.pdf) for details.\n",
    "- `\"lora_bias\"`: LoRA Adaptors + bias parameters.\n",
    "- `\"lora_norm\"`: LoRA Adaptors + normalization parameters + bias parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdee4196",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"optimization.efficient_finetune\": None})\n",
    "# finetune only bias parameters\n",
    "predictor.fit(hyperparameters={\"optimization.efficient_finetune\": \"bit_fit\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e6c8a",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "### env.num_gpus\n",
    "The number of gpus to use. If given -1, we count the GPUs by `env.num_gpus = torch.cuda.device_count()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a6ba63",
   "metadata": {},
   "source": [
    "```\n",
    "# by default, all available gpus are used by AutoMM\n",
    "predictor.fit(hyperparameters={\"env.num_gpus\": -1})\n",
    "# use 1 gpu only\n",
    "predictor.fit(hyperparameters={\"env.num_gpus\": 1})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f34b36",
   "metadata": {},
   "source": [
    "### env.per_gpu_batch_size\n",
    "The batch size for each GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e1d36",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"env.per_gpu_batch_size\": 8})\n",
    "# use batch size 16 per GPU\n",
    "predictor.fit(hyperparameters={\"env.per_gpu_batch_size\": 16})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37e632",
   "metadata": {},
   "source": [
    "### env.batch_size\n",
    "The batch size to use in each step of training. If `env.batch_size` is larger than `env.per_gpu_batch_size * env.num_gpus`, we accumulate gradients to reach the effective `env.batch_size` before performing one optimization step. The accumulation steps are calculated by `env.batch_size // (env.per_gpu_batch_size * env.num_gpus)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f9cdb",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"env.batch_size\": 128})\n",
    "# use batch size 256\n",
    "predictor.fit(hyperparameters={\"env.batch_size\": 256})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f821a",
   "metadata": {},
   "source": [
    "### env.eval_batch_size_ratio\n",
    "Prediction or evaluation uses a larger per gpu batch size `env.per_gpu_batch_size * env.eval_batch_size_ratio`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f2686e",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"env.eval_batch_size_ratio\": 4})\n",
    "# use 2x per gpu batch size during prediction or evalution\n",
    "predictor.fit(hyperparameters={\"env.eval_batch_size_ratio\": 2})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b390061",
   "metadata": {},
   "source": [
    "### env.precision\n",
    "Support either double (`64`), float (`32`), bfloat16 (`\"bf16\"`), or half (`16`) precision training.\n",
    "\n",
    "Half precision, or mixed precision, is the combined use of 32 and 16 bit floating points to reduce memory footprint during model training. This can result in improved performance, achieving +3x speedups on modern GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae338db",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"env.precision\": 16})\n",
    "# use bfloat16\n",
    "predictor.fit(hyperparameters={\"env.precision\": \"bf16\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00670d6e",
   "metadata": {},
   "source": [
    "### env.num_workers\n",
    "The number of worker processes used by the Pytorch dataloader in training. Note that more workers don't always bring speedup especially when `env.strategy = \"ddp_spawn\"`. \n",
    "For more details, see the guideline [here](https://pytorch-lightning.readthedocs.io/en/stable/accelerators/gpu.html#distributed-data-parallel)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c719f8aa",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"env.num_workers\": 2})\n",
    "# use 4 workers in the training dataloader\n",
    "predictor.fit(hyperparameters={\"env.num_workers\": 4})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4060e4b9",
   "metadata": {},
   "source": [
    "### env.num_workers_evaluation\n",
    "The number of worker processes used by the Pytorch dataloader in prediction or evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58093ccf",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"env.num_workers_evaluation\": 2})\n",
    "# use 4 workers in the prediction/evaluation dataloader\n",
    "predictor.fit(hyperparameters={\"env.num_workers_evaluation\": 4})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727457d",
   "metadata": {},
   "source": [
    "### env.strategy\n",
    "Distributed training mode.\n",
    "\n",
    "- `\"dp\"`: data parallel.\n",
    "- `\"ddp\"`: distributed data parallel (python script based).\n",
    "- `\"ddp_spawn\"`: distributed data parallel (spawn based).\n",
    "\n",
    "See [here](https://pytorch-lightning.readthedocs.io/en/stable/accelerators/gpu.html#distributed-modes) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b74ca",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"env.strategy\": \"ddp_spawn\"})\n",
    "# use ddp during training\n",
    "predictor.fit(hyperparameters={\"env.strategy\": \"ddp\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2389c903",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### model.names\n",
    "Choose what types of models to use.\n",
    "\n",
    "- `\"hf_text\"`: the pretrained text models from [Huggingface](https://huggingface.co/).\n",
    "- `\"timm_image\"`: the pretrained image models from [TIMM](https://github.com/rwightman/pytorch-image-models/tree/master/timm/models).\n",
    "- `\"clip\"`: the pretrained CLIP models.\n",
    "- `\"categorical_mlp\"`: MLP for categorical data.\n",
    "- `\"numerical_mlp\"`: MLP for numerical data.\n",
    "- `\"categorical_transformer\"`: [FT-Transformer](https://arxiv.org/pdf/2106.11959.pdf) for categorical data.\n",
    "- `\"numerical_transformer\"`: [FT-Transformer](https://arxiv.org/pdf/2106.11959.pdf) for numerical data.\n",
    "- `\"fusion_mlp\"`: MLP-based fusion for features from multiple backbones.\n",
    "- `\"fusion_transformer\"`: transformer-based fusion for features from multiple backbones.\n",
    "\n",
    "If no data of one modality is detected, the related model types will be automatically removed in training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c04e1c",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"model.names\": [\"hf_text\", \"timm_image\", \"clip\", \"categorical_mlp\", \"numerical_mlp\", \"fusion_mlp\"]})\n",
    "# use only text models\n",
    "predictor.fit(hyperparameters={\"model.names\": [\"hf_text\"]})\n",
    "# use only image models\n",
    "predictor.fit(hyperparameters={\"model.names\": [\"timm_image\"]})\n",
    "# use only clip models\n",
    "predictor.fit(hyperparameters={\"model.names\": [\"clip\"]})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40a5bc7",
   "metadata": {},
   "source": [
    "### model.hf_text.checkpoint_name\n",
    "Specify a text backbone supported by the Hugginface [AutoModel](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodel)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843cf04",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"model.hf_text.checkpoint_name\": \"google/electra-base-discriminator\"})\n",
    "# choose roberta base\n",
    "predictor.fit(hyperparameters={\"model.hf_text.checkpoint_name\": \"roberta-base\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae55770",
   "metadata": {},
   "source": [
    "### model.timm_image.checkpoint_name\n",
    "Select an image backbone from [TIMM](https://github.com/rwightman/pytorch-image-models/tree/master/timm/models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be919db3",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"model.timm_image.checkpoint_name\": \"swin_base_patch4_window7_224\"})\n",
    "# choose a vit base\n",
    "predictor.fit(hyperparameters={\"model.timm_image.checkpoint_name\": \"vit_base_patch32_224\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0902576c",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### data.image.missing_value_strategy\n",
    "How to deal with missing images, opening which fails.\n",
    "\n",
    "- `\"skip\"`: skip a sample with missing images.\n",
    "- `\"zero\"`: use zero image to replace a missing image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db0cf44",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.image.missing_value_strategy\": \"skip\"})\n",
    "# use zero image\n",
    "predictor.fit(hyperparameters={\"data.image.missing_value_strategy\": \"zero\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17544667",
   "metadata": {},
   "source": [
    "### data.categorical.convert_to_text\n",
    "Whether to treat categorical data as text. If True, no categorical models, e.g., `\"categorical_mlp\"` and `\"categorical_transformer\"`, would be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dda49c",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.categorical.convert_to_text\": True})\n",
    "# turn off the conversion\n",
    "predictor.fit(hyperparameters={\"data.categorical.convert_to_text\": False})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fccdb0b",
   "metadata": {},
   "source": [
    "### data.numerical.convert_to_text\n",
    "Whether to convert numerical data to text. If True, no numerical models e.g., `\"numerical_mlp\"` and `\"numerical_transformer\"`, would be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f37849a",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.numerical.convert_to_text\": False})\n",
    "# turn on the conversion\n",
    "predictor.fit(hyperparameters={\"data.numerical.convert_to_text\": True})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd401f",
   "metadata": {},
   "source": [
    "### data.numerical.scaler_with_mean\n",
    "If True, center the numerical data (not including the numerical labels) before scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f2e89",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.numerical.scaler_with_mean\": True})\n",
    "# turn off centering\n",
    "predictor.fit(hyperparameters={\"data.numerical.scaler_with_mean\": False})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d14ec",
   "metadata": {},
   "source": [
    "### data.numerical.scaler_with_std\n",
    "If True, scale the numerical data (not including the numerical labels) to unit variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22bbbb1",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.numerical.scaler_with_std\": True})\n",
    "# turn off scaling\n",
    "predictor.fit(hyperparameters={\"data.numerical.scaler_with_std\": False})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e999f2",
   "metadata": {},
   "source": [
    "### data.label.numerical_label_preprocessing\n",
    "How to process the numerical labels in regression tasks.\n",
    "\n",
    "- `\"standardscaler\"`: standardizes numerical labels by removing the mean and scaling to unit variance.\n",
    "- `\"minmaxscaler\"`: transforms numerical labels by scaling each feature to range (0, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9eb2c",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.label.numerical_label_preprocessing\": \"standardscaler\"})\n",
    "# scale numerical labels to (0, 1)\n",
    "predictor.fit(hyperparameters={\"data.label.numerical_label_preprocessing\": \"minmaxscaler\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61870c9",
   "metadata": {},
   "source": [
    "### data.pos_label\n",
    "The positive label in a binary classification task. Users need to specify this label to properly use some metrics, e.g., roc_auc, average_precision, and f1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c415a",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.pos_label\": None})\n",
    "# assume the labels are [\"changed\", \"not changed\"] and \"changed\" is the positive label\n",
    "predictor.fit(hyperparameters={\"data.pos_label\": \"changed\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba70bd57",
   "metadata": {},
   "source": [
    "### data.mixup.turn_on\n",
    "If True, use Mixup in training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba97a66c",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.mixup.turn_on\": False})\n",
    "# turn on Mixup\n",
    "predictor.fit(hyperparameters={\"data.mixup.turn_on\": True})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97530a2",
   "metadata": {},
   "source": [
    "### data.mixup.mixup_alpha\n",
    "Mixup alpha value. Mixup is active if `data.mixup.mixup_alpha` > 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d3f6b",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.mixup.mixup_alpha\": 0.8})\n",
    "# set it to 1.0 to turn off Mixup\n",
    "predictor.fit(hyperparameters={\"data.mixup.mixup_alpha\": 1.0})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b1c30",
   "metadata": {},
   "source": [
    "### data.mixup.cutmix_alpha\n",
    "Cutomix alpha value. Cutomix is active if `data.mixup.cutmix_alpha` > 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54b285",
   "metadata": {},
   "source": [
    "```\n",
    "# by default, Cutmix is turned off by using alpha 1.0\n",
    "predictor.fit(hyperparameters={\"data.mixup.cutmix_alpha\": 1.0})\n",
    "# turn it on by choosing a number in range (0, 1)\n",
    "predictor.fit(hyperparameters={\"data.mixup.cutmix_alpha\": 0.8})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f19e4",
   "metadata": {},
   "source": [
    "### data.mixup.prob\n",
    "The probability of conducting Mixup or Cutmix if enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f2743",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.mixup.prob\": 1.0})\n",
    "# set probability to 0.5\n",
    "predictor.fit(hyperparameters={\"data.mixup.prob\": 0.5})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121eb2c",
   "metadata": {},
   "source": [
    "### data.mixup.switch_prob\n",
    "The probability of switching to Cutmix instead of Mixup when both are active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11472e4a",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.mixup.switch_prob\": 0.5})\n",
    "# set probability to 0.7\n",
    "predictor.fit(hyperparameters={\"data.mixup.switch_prob\": 0.7})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed041e7",
   "metadata": {},
   "source": [
    "### data.mixup.mode\n",
    "How to apply Mixup or Cutmix params (per `\"batch\"`, `\"pair\"` (pair of elements), `\"elem\"` (element)).\n",
    "See [here](https://github.com/rwightman/pytorch-image-models/blob/d30685c283137b4b91ea43c4e595c964cd2cb6f0/timm/data/mixup.py#L211-L216) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc30ab40",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.mixup.mode\": \"batch\"})\n",
    "# use \"pair\"\n",
    "predictor.fit(hyperparameters={\"data.mixup.mode\": \"pair\"})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355ea29",
   "metadata": {},
   "source": [
    "### data.mixup.label_smoothing\n",
    "Apply label smoothing to the mixed label tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ac4ed",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.mixup.label_smoothing\": 0.1})\n",
    "# set it to 0.2\n",
    "predictor.fit(hyperparameters={\"data.mixup.label_smoothing\": 0.2})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab32792",
   "metadata": {},
   "source": [
    "### data.mixup.turn_off_epoch\n",
    "Stop Mixup or Cutmix after reaching this number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecdfab1",
   "metadata": {},
   "source": [
    "```\n",
    "# default used by AutoMM\n",
    "predictor.fit(hyperparameters={\"data.mixup.turn_off_epoch\": 5})\n",
    "# turn off mixup after 7 epochs\n",
    "predictor.fit(hyperparameters={\"data.mixup.turn_off_epoch\": 7})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb36341d",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"../utils/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n",
    "\n",
    "# Thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68768fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
