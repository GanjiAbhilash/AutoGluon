{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2cf8fa",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"./utils/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n",
    "\n",
    "# <a name=\"0\"> Image Classification using AutoGluon </a>\n",
    "\n",
    "In this notebook, we will load images and the corresponding labels into [AutoGluon](https://autogluon.mxnet.io/index.html) and use this data to obtain a neural network that can classify new images. This is different from traditional machine learning where we need to manually define the neural network and then specify the hyperparameters in the training process. Instead, with just a single call to AutoGluon’s fit function, AutoGluon automatically trains many models with different hyperparameter configurations and returns the model that achieved the highest level of accuracy.\n",
    "    \n",
    "1. <a href=\"#Download-the-Image-Dataset\">Download the Image Dataset</a>\n",
    "2. <a href=\"#AutoGluon-ImagePredictor\">AutoGluon ImagePredictor</a>\n",
    "3. <a href=\"#AutoGluon-Training-Results\">AutoGluon Training Results</a>\n",
    "4. <a href=\"#Generate-image-features-with-a-classifier\">Generate image features with a classifier</a>\n",
    "5. <a href=\"#Making-Predictions-with-ImagePredictor\">Making Predictions with ImagePredictor</a>\n",
    "6. <a href=\"#Search-Space-and-Hyperparameter-Optimization\">Search Space and Hyperparameter Optimization</a>\n",
    "\n",
    "Note: Please use **GPU** for training. CPU training will lead to an unceasing running script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb004e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AutoGluon\n",
    "# ! pip install -q autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83a0d32",
   "metadata": {},
   "source": [
    "Let's import the ImagePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decf786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.7.0` and `torch==1.10.1+cu102` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
      "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
     ]
    }
   ],
   "source": [
    "from autogluon.vision import ImagePredictor\n",
    "import autogluon.core as ag\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc427b5",
   "metadata": {},
   "source": [
    "To use AutoGluon for computer vision task training, we need to organize our data with the following structure:\n",
    "\n",
    "    data/\n",
    "    ├── train/\n",
    "        ├── class1/\n",
    "        ├── class2/\n",
    "        ├── class3/\n",
    "        ├── ...\n",
    "    ├── test/\n",
    "        ├── class1/\n",
    "        ├── class2/\n",
    "        ├── class3/\n",
    "        ├── ...\n",
    "\n",
    "Here each subfolder contains all images that belong to that category, e.g., `class1` contains all images belonging to the first class. We generally recommend at least 100 training images per class for reasonable classification performance, but this might depend on the type of images in your specific use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b522926",
   "metadata": {},
   "source": [
    "## <a id=\"Download-the-Image-Dataset\">Download the Image Dataset</a>\n",
    "For demonstration purposes, we use a subset of the __Shopee-IET__ dataset from [Kaggle](https://www.kaggle.com/competitions). Each image in this data depicts a clothing item and the corresponding label specifies its clothing category. Our subset of the data contains the following possible labels: BabyPants, BabyShirt, womencasualshoes, womenchiffontop.\n",
    "\n",
    "We download the data subset and create training/test dataset folders like below. If you use this on your own dataset, just point it to your training or test folder. Example: `train_dataset = ImagePredictor.Dataset.from_folder('mydataset/train')`\n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf94ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/\n",
      "├── test/\n",
      "└── train/\n"
     ]
    }
   ],
   "source": [
    "path = 'https://autogluon.s3.amazonaws.com/datasets/shopee-iet.zip'\n",
    "df_train, _, df_test = ImagePredictor.Dataset.from_folders(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741cab7f",
   "metadata": {},
   "source": [
    "Let's print the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cfc6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 image  label\n",
      "0    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "1    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "2    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "3    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "4    /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      0\n",
      "..                                                 ...    ...\n",
      "795  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "796  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "797  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "798  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "799  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...      3\n",
      "\n",
      "[800 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea354d8a",
   "metadata": {},
   "source": [
    "##  <a id=\"AutoGluon-ImagePredictor\">AutoGluon ImagePredictor</a>\n",
    "\n",
    "Now, let's fit a __classifier__ using AutoGluon [predictor.fit()](https://auto.gluon.ai/stable/tutorials/image_prediction/beginner.html). Within fit, the dataset is __automatically__ split into training and validation sets. The model with the best hyperparameter configuration is selected based on its performance on the __validation set__.\n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e318e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluoncv.auto.tasks.image_classification:Randomly split train_data into train[716]/validation[84] splits.\n",
      "INFO:gluoncv.auto.tasks.image_classification:Starting fit without HPO\n",
      "INFO:ImageClassificationEstimator:modified configs(<old> != <new>): {\n",
      "INFO:ImageClassificationEstimator:root.img_cls.model   resnet50_v1 != resnet50_v1b\n",
      "INFO:ImageClassificationEstimator:root.valid.batch_size 128 != 16\n",
      "INFO:ImageClassificationEstimator:root.train.lr        0.1 != 0.01\n",
      "INFO:ImageClassificationEstimator:root.train.data_dir  ~/.mxnet/datasets/imagenet != auto\n",
      "INFO:ImageClassificationEstimator:root.train.rec_train ~/.mxnet/datasets/imagenet/rec/train.rec != auto\n",
      "INFO:ImageClassificationEstimator:root.train.batch_size 128 != 16\n",
      "INFO:ImageClassificationEstimator:root.train.rec_train_idx ~/.mxnet/datasets/imagenet/rec/train.idx != auto\n",
      "INFO:ImageClassificationEstimator:root.train.num_training_samples 1281167 != -1\n",
      "INFO:ImageClassificationEstimator:root.train.epochs    10 != 15\n",
      "INFO:ImageClassificationEstimator:root.train.rec_val_idx ~/.mxnet/datasets/imagenet/rec/val.idx != auto\n",
      "INFO:ImageClassificationEstimator:root.train.rec_val   ~/.mxnet/datasets/imagenet/rec/val.rec != auto\n",
      "INFO:ImageClassificationEstimator:}\n",
      "INFO:ImageClassificationEstimator:Saved config to /home/ec2-user/SageMaker/MLU-WKSP-Tuning-Autogluon/notebooks/AutogluonModels/Image/07767bde/.trial_0/config.yaml\n",
      "WARNING:ImageClassificationEstimator:No gpu detected, fallback to cpu. You can ignore this warning if this is intended.\n",
      "INFO:ImageClassificationEstimator:Start training from [Epoch 0]\n",
      "INFO:ImageClassificationEstimator:[Epoch 0] training: accuracy=0.474432\n",
      "INFO:ImageClassificationEstimator:[Epoch 0] speed: 2 samples/sec\ttime cost: 330.696526\n",
      "INFO:ImageClassificationEstimator:[Epoch 0] validation: top1=0.750000 top5=1.000000\n",
      "INFO:ImageClassificationEstimator:[Epoch 0] Current best top-1: 0.750000 vs previous -inf, saved to /home/ec2-user/SageMaker/MLU-WKSP-Tuning-Autogluon/notebooks/AutogluonModels/Image/07767bde/.trial_0/best_checkpoint.pkl\n",
      "WARNING:ImageClassificationEstimator:`time_limit=599.990339756012` reached, exit early...\n",
      "INFO:ImageClassificationEstimator:Applying the state from the best checkpoint...\n",
      "INFO:gluoncv.auto.tasks.image_classification:Finished, total runtime is 619.88 s\n",
      "INFO:gluoncv.auto.tasks.image_classification:{ 'best_config': { 'batch_size': 16,\n",
      "                   'dist_ip_addrs': None,\n",
      "                   'epochs': 15,\n",
      "                   'estimator': <class 'gluoncv.auto.estimators.image_classification.image_classification.ImageClassificationEstimator'>,\n",
      "                   'final_fit': False,\n",
      "                   'gpus': [0],\n",
      "                   'log_dir': 'AutogluonModels/Image/07767bde',\n",
      "                   'lr': 0.01,\n",
      "                   'model': 'resnet50_v1b',\n",
      "                   'ngpus_per_trial': 1,\n",
      "                   'nthreads_per_trial': 128,\n",
      "                   'num_trials': 1,\n",
      "                   'num_workers': 4,\n",
      "                   'problem_type': 'multiclass',\n",
      "                   'search_strategy': 'random',\n",
      "                   'seed': 647,\n",
      "                   'time_limits': 600,\n",
      "                   'wall_clock_tick': 1659562789.3028562},\n",
      "  'total_time': 608.5926694869995,\n",
      "  'train_acc': 0.4744318181818182,\n",
      "  'valid_acc': 0.75}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.vision.predictor.predictor.ImagePredictor at 0x7f25ada95898>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = ImagePredictor(path=\"AutogluonModels/Image\")\n",
    "\n",
    "time_limit = 10 * 60 # how long fit() should run (in seconds)\n",
    "predictor.fit(df_train,\n",
    "              #epochs=10,\n",
    "              time_limit=time_limit,\n",
    "              ngpus_per_trial=1\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a184369",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.save(\"AutogluonModels/Image/ImagePredictor.ag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e868ac",
   "metadata": {},
   "source": [
    "##  <a id=\"AutoGluon-Training-Results\">AutoGluon Training Results</a>\n",
    " \n",
    "Autogluon also provides the training results, which can be accessed by calling `predictor.fit_summary()`. \n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c8f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6998f346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_acc': 0.4744318181818182,\n",
       " 'valid_acc': 0.75,\n",
       " 'total_time': 608.5926694869995,\n",
       " 'best_config': {'model': 'resnet50_v1b',\n",
       "  'lr': 0.01,\n",
       "  'num_trials': 1,\n",
       "  'epochs': 15,\n",
       "  'batch_size': 16,\n",
       "  'nthreads_per_trial': 128,\n",
       "  'ngpus_per_trial': 1,\n",
       "  'time_limits': 600,\n",
       "  'search_strategy': 'random',\n",
       "  'dist_ip_addrs': None,\n",
       "  'log_dir': 'AutogluonModels/Image/07767bde',\n",
       "  'num_workers': 4,\n",
       "  'gpus': [0],\n",
       "  'seed': 647,\n",
       "  'final_fit': False,\n",
       "  'estimator': gluoncv.auto.estimators.image_classification.image_classification.ImageClassificationEstimator,\n",
       "  'wall_clock_tick': 1659562789.3028562,\n",
       "  'problem_type': 'multiclass'},\n",
       " 'fit_history': {'train_acc': 0.4744318181818182,\n",
       "  'valid_acc': 0.75,\n",
       "  'total_time': 608.5926694869995,\n",
       "  'best_config': {'model': 'resnet50_v1b',\n",
       "   'lr': 0.01,\n",
       "   'num_trials': 1,\n",
       "   'epochs': 15,\n",
       "   'batch_size': 16,\n",
       "   'nthreads_per_trial': 128,\n",
       "   'ngpus_per_trial': 1,\n",
       "   'time_limits': 600,\n",
       "   'search_strategy': 'random',\n",
       "   'dist_ip_addrs': None,\n",
       "   'log_dir': 'AutogluonModels/Image/07767bde',\n",
       "   'num_workers': 4,\n",
       "   'gpus': [0],\n",
       "   'seed': 647,\n",
       "   'final_fit': False,\n",
       "   'estimator': gluoncv.auto.estimators.image_classification.image_classification.ImageClassificationEstimator,\n",
       "   'wall_clock_tick': 1659562789.3028562,\n",
       "   'problem_type': 'multiclass'}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0347eb",
   "metadata": {},
   "source": [
    "We can access certain results from this summary. For example, training and validation accuracies below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bfabfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.474, val acc: 0.750\n"
     ]
    }
   ],
   "source": [
    "print('Train acc: %.3f, val acc: %.3f' %(fit_result['train_acc'], fit_result['valid_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752f01b3",
   "metadata": {},
   "source": [
    "The best model and optimum hyperparameters: Learning rate, batch size, epochs can be printed with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b4ef70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'resnet50_v1b',\n",
       " 'lr': 0.01,\n",
       " 'num_trials': 1,\n",
       " 'epochs': 15,\n",
       " 'batch_size': 16,\n",
       " 'nthreads_per_trial': 128,\n",
       " 'ngpus_per_trial': 1,\n",
       " 'time_limits': 600,\n",
       " 'search_strategy': 'random',\n",
       " 'dist_ip_addrs': None,\n",
       " 'log_dir': 'AutogluonModels/Image/07767bde',\n",
       " 'num_workers': 4,\n",
       " 'gpus': [0],\n",
       " 'seed': 647,\n",
       " 'final_fit': False,\n",
       " 'estimator': gluoncv.auto.estimators.image_classification.image_classification.ImageClassificationEstimator,\n",
       " 'wall_clock_tick': 1659562789.3028562,\n",
       " 'problem_type': 'multiclass'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_result['fit_history']['best_config']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736078db",
   "metadata": {},
   "source": [
    "##  <a id=\"Generate-image-features-with-a-classifier\">Generate image features with a classifier</a>\n",
    "\n",
    "Extracting representation from the whole image learned by a model is also very useful. The `predict_feature` function returns a vector of image features.\n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8056b549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       image_feature\n",
      "0  [0.3753202, 0.0, 0.31749323, 1.2149992, 0.6535...\n"
     ]
    }
   ],
   "source": [
    "image_path = df_test.iloc[0]['image']\n",
    "feature = predictor.predict_feature(image_path)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8eec62",
   "metadata": {},
   "source": [
    "##  <a id=\"Making-Predictions-with-ImagePredictor\">Making Predictions with ImagePredictor</a>\n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a8688",
   "metadata": {},
   "source": [
    "We can call the predict function to run on different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a432832e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BabyShirt</td>\n",
       "      <td>0.488706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class     score  id\n",
       "0  BabyShirt  0.488706   1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = df_test.iloc[0]['image']\n",
    "predictor.predict(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f139fae0",
   "metadata": {},
   "source": [
    "Let's get predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c98b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               class     score  id  \\\n",
      "0          BabyShirt  0.488706   1   \n",
      "1          BabyShirt  0.887769   1   \n",
      "2          BabyShirt  0.432509   1   \n",
      "3   womencasualshoes  0.593805   2   \n",
      "4          BabyShirt  0.790615   1   \n",
      "..               ...       ...  ..   \n",
      "75   womenchiffontop  0.733472   3   \n",
      "76   womenchiffontop  0.360697   3   \n",
      "77   womenchiffontop  0.780986   3   \n",
      "78         BabyPants  0.484973   0   \n",
      "79   womenchiffontop  0.742945   3   \n",
      "\n",
      "                                                image  \n",
      "0   /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "1   /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "2   /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "3   /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "4   /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "..                                                ...  \n",
      "75  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "76  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "77  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "78  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "79  /home/ec2-user/.gluoncv/datasets/shopee-iet/da...  \n",
      "\n",
      "[80 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "pred = predictor.predict(df_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "358429b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.675, 1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate image predictor on test data rather than retrieving predictions\n",
    "predictor.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a362448",
   "metadata": {},
   "source": [
    "## <a id=\"Search-Space-and-Hyperparameter-Optimization\">Search Space and Hyperparameter Optimization</a>\n",
    "\n",
    "This section dives into a few options for advanced control over ImagePredictor's fitting process such as specifying which:\n",
    "\n",
    "- Networks to Try\n",
    "- Training Hyperparameters\n",
    "- Search Algorithms\n",
    "\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18c4eb",
   "metadata": {},
   "source": [
    "### Specify which Networks to Try\n",
    "We start with specifying the pretrained neural network candidates. Given such a list, AutoGluon tries to train different networks from this list to identify the best-performing candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224c8fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('resnet18_v1',\n",
       " 'resnet34_v1',\n",
       " 'resnet50_v1',\n",
       " 'resnet101_v1',\n",
       " 'resnet152_v1',\n",
       " 'resnet18_v2',\n",
       " 'resnet34_v2',\n",
       " 'resnet50_v2',\n",
       " 'resnet101_v2',\n",
       " 'resnet152_v2',\n",
       " 'resnest14',\n",
       " 'resnest26',\n",
       " 'resnest50',\n",
       " 'resnest101',\n",
       " 'resnest200',\n",
       " 'resnest269',\n",
       " 'se_resnet18_v1',\n",
       " 'se_resnet34_v1',\n",
       " 'se_resnet50_v1',\n",
       " 'se_resnet101_v1',\n",
       " 'se_resnet152_v1',\n",
       " 'se_resnet18_v2',\n",
       " 'se_resnet34_v2',\n",
       " 'se_resnet50_v2',\n",
       " 'se_resnet101_v2',\n",
       " 'se_resnet152_v2',\n",
       " 'vgg11',\n",
       " 'vgg13',\n",
       " 'vgg16',\n",
       " 'vgg19',\n",
       " 'vgg11_bn',\n",
       " 'vgg13_bn',\n",
       " 'vgg16_bn',\n",
       " 'vgg19_bn',\n",
       " 'alexnet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'squeezenet1.0',\n",
       " 'squeezenet1.1',\n",
       " 'googlenet',\n",
       " 'inceptionv3',\n",
       " 'xception',\n",
       " 'xception71',\n",
       " 'mobilenet1.0',\n",
       " 'mobilenet0.75',\n",
       " 'mobilenet0.5',\n",
       " 'mobilenet0.25',\n",
       " 'mobilenetv2_1.0',\n",
       " 'mobilenetv2_0.75',\n",
       " 'mobilenetv2_0.5',\n",
       " 'mobilenetv2_0.25',\n",
       " 'mobilenetv3_large',\n",
       " 'mobilenetv3_small',\n",
       " 'cifar_resnet20_v1',\n",
       " 'cifar_resnet56_v1',\n",
       " 'cifar_resnet110_v1',\n",
       " 'cifar_resnet20_v2',\n",
       " 'cifar_resnet56_v2',\n",
       " 'cifar_resnet110_v2',\n",
       " 'cifar_wideresnet16_10',\n",
       " 'cifar_wideresnet28_10',\n",
       " 'cifar_wideresnet40_8',\n",
       " 'cifar_resnext29_32x4d',\n",
       " 'cifar_resnext29_16x64d',\n",
       " 'resnet18_v1b',\n",
       " 'resnet34_v1b',\n",
       " 'resnet50_v1b',\n",
       " 'resnet50_v1b_gn',\n",
       " 'resnet101_v1b_gn',\n",
       " 'resnet101_v1b',\n",
       " 'resnet152_v1b',\n",
       " 'resnet50_v1c',\n",
       " 'resnet101_v1c',\n",
       " 'resnet152_v1c',\n",
       " 'resnet50_v1d',\n",
       " 'resnet101_v1d',\n",
       " 'resnet152_v1d',\n",
       " 'resnet50_v1e',\n",
       " 'resnet101_v1e',\n",
       " 'resnet152_v1e',\n",
       " 'resnet50_v1s',\n",
       " 'resnet101_v1s',\n",
       " 'resnet152_v1s',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_64x4d',\n",
       " 'resnext101e_64x4d',\n",
       " 'se_resnext50_32x4d',\n",
       " 'se_resnext101_32x4d',\n",
       " 'se_resnext101_64x4d',\n",
       " 'se_resnext101e_64x4d',\n",
       " 'senet_154',\n",
       " 'senet_154e',\n",
       " 'darknet53',\n",
       " 'nasnet_4_1056',\n",
       " 'nasnet_5_1538',\n",
       " 'nasnet_7_1920',\n",
       " 'nasnet_6_4032',\n",
       " 'residualattentionnet56',\n",
       " 'residualattentionnet92',\n",
       " 'residualattentionnet128',\n",
       " 'residualattentionnet164',\n",
       " 'residualattentionnet200',\n",
       " 'residualattentionnet236',\n",
       " 'residualattentionnet452',\n",
       " 'cifar_residualattentionnet56',\n",
       " 'cifar_residualattentionnet92',\n",
       " 'cifar_residualattentionnet452',\n",
       " 'resnet18_v1b_0.89',\n",
       " 'resnet50_v1d_0.86',\n",
       " 'resnet50_v1d_0.48',\n",
       " 'resnet50_v1d_0.37',\n",
       " 'resnet50_v1d_0.11',\n",
       " 'resnet101_v1d_0.76',\n",
       " 'resnet101_v1d_0.73',\n",
       " 'mobilenet1.0_int8',\n",
       " 'resnet50_v1_int8',\n",
       " 'i3d_resnet50_v1_custom',\n",
       " 'slowfast_4x16_resnet50_custom',\n",
       " 'resnet50_v1b_custom',\n",
       " 'resnet18_v1b_custom',\n",
       " 'dla34',\n",
       " 'hrnet_w18_c',\n",
       " 'hrnet_w18_small_v1_c',\n",
       " 'hrnet_w18_small_v2_c',\n",
       " 'hrnet_w30_c',\n",
       " 'hrnet_w32_c',\n",
       " 'hrnet_w40_c',\n",
       " 'hrnet_w44_c',\n",
       " 'hrnet_w48_c',\n",
       " 'hrnet_w64_c',\n",
       " 'hrnet_w18_small_v1_s',\n",
       " 'hrnet_w18_small_v2_s',\n",
       " 'hrnet_w48_s')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you may choose more than 70+ available model in the model zoo provided by GluonCV:\n",
    "model_list = ImagePredictor.list_models()\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d319d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a list of networks for AutoGluon to try\n",
    "model = ag.Categorical('resnet18_v1b', 'mobilenetv3_small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2eabfe",
   "metadata": {},
   "source": [
    "### Specify the Training Hyperparameters\n",
    "We can manually specify many crucial hyper-parameters, with specific value or search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b95a70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the batch size value and learning rate search space \n",
    "batch_size = 8\n",
    "lr = ag.Categorical(1e-2, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025a810",
   "metadata": {},
   "source": [
    "### Specify the Search Algorithms\n",
    "Beyond simply specifying the space of hyperparameter configurations to search over, you can also tell AutoGluon what strategy it should employ to actually search through this space. This process of finding good hyperparameters from a given search space is commonly referred to as hyperparameter optimization (HPO) or hyperparameter tuning\n",
    "\n",
    "We would be using random search for HPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3532162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gluoncv.auto.tasks.image_classification:The number of requested GPUs is greater than the number of available GPUs.Reduce the number to 1\n",
      "INFO:gluoncv.auto.tasks.image_classification:Randomly split train_data into train[731]/validation[69] splits.\n",
      "INFO:gluoncv.auto.tasks.image_classification:Starting fit without HPO\n",
      "INFO:ImageClassificationEstimator:modified configs(<old> != <new>): {\n",
      "INFO:ImageClassificationEstimator:root.img_cls.model   resnet50_v1 != resnet18_v1b\n",
      "INFO:ImageClassificationEstimator:root.valid.batch_size 128 != 8\n",
      "INFO:ImageClassificationEstimator:root.train.lr        0.1 != 0.01\n",
      "INFO:ImageClassificationEstimator:root.train.data_dir  ~/.mxnet/datasets/imagenet != auto\n",
      "INFO:ImageClassificationEstimator:root.train.rec_train ~/.mxnet/datasets/imagenet/rec/train.rec != auto\n",
      "INFO:ImageClassificationEstimator:root.train.batch_size 128 != 8\n",
      "INFO:ImageClassificationEstimator:root.train.rec_train_idx ~/.mxnet/datasets/imagenet/rec/train.idx != auto\n",
      "INFO:ImageClassificationEstimator:root.train.num_training_samples 1281167 != -1\n",
      "INFO:ImageClassificationEstimator:root.train.epochs    10 != 2\n",
      "INFO:ImageClassificationEstimator:root.train.rec_val_idx ~/.mxnet/datasets/imagenet/rec/val.idx != auto\n",
      "INFO:ImageClassificationEstimator:root.train.rec_val   ~/.mxnet/datasets/imagenet/rec/val.rec != auto\n",
      "INFO:ImageClassificationEstimator:}\n",
      "INFO:ImageClassificationEstimator:Saved config to /home/ec2-user/SageMaker/MLU-WKSP-Tuning-Autogluon/notebooks/0e651630/.trial_0/config.yaml\n",
      "WARNING:ImageClassificationEstimator:No gpu detected, fallback to cpu. You can ignore this warning if this is intended.\n",
      "INFO:root:Model file not found. Downloading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/.mxnet/models/resnet18_v1b-2d9d980c.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet18_v1b-2d9d980c.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42433KB [00:01, 36670.24KB/s]                           \n",
      "INFO:ImageClassificationEstimator:Start training from [Epoch 0]\n",
      "INFO:ImageClassificationEstimator:Epoch[0] Batch [49]\tSpeed: 4.921916 samples/sec\taccuracy=0.422500\tlr=0.010000\n",
      "INFO:ImageClassificationEstimator:[Epoch 0] training: accuracy=0.464286\n",
      "INFO:ImageClassificationEstimator:[Epoch 0] speed: 4 samples/sec\ttime cost: 146.568436\n",
      "INFO:ImageClassificationEstimator:[Epoch 0] validation: top1=0.695652 top5=1.000000\n",
      "INFO:ImageClassificationEstimator:[Epoch 0] Current best top-1: 0.695652 vs previous -inf, saved to /home/ec2-user/SageMaker/MLU-WKSP-Tuning-Autogluon/notebooks/0e651630/.trial_0/best_checkpoint.pkl\n",
      "INFO:ImageClassificationEstimator:Epoch[1] Batch [49]\tSpeed: 4.909809 samples/sec\taccuracy=0.605000\tlr=0.010000\n",
      "INFO:ImageClassificationEstimator:[Epoch 1] training: accuracy=0.627747\n",
      "INFO:ImageClassificationEstimator:[Epoch 1] speed: 4 samples/sec\ttime cost: 148.307698\n",
      "INFO:ImageClassificationEstimator:[Epoch 1] validation: top1=0.768116 top5=1.000000\n",
      "INFO:ImageClassificationEstimator:[Epoch 1] Current best top-1: 0.768116 vs previous 0.695652, saved to /home/ec2-user/SageMaker/MLU-WKSP-Tuning-Autogluon/notebooks/0e651630/.trial_0/best_checkpoint.pkl\n",
      "INFO:ImageClassificationEstimator:Applying the state from the best checkpoint...\n",
      "INFO:gluoncv.auto.tasks.image_classification:Finished, total runtime is 314.18 s\n",
      "INFO:gluoncv.auto.tasks.image_classification:{ 'best_config': { 'batch_size': 8,\n",
      "                   'dist_ip_addrs': None,\n",
      "                   'epochs': 2,\n",
      "                   'estimator': <class 'gluoncv.auto.estimators.image_classification.image_classification.ImageClassificationEstimator'>,\n",
      "                   'final_fit': False,\n",
      "                   'gpus': [0],\n",
      "                   'log_dir': '/home/ec2-user/SageMaker/MLU-WKSP-Tuning-Autogluon/notebooks/0e651630',\n",
      "                   'lr': 0.01,\n",
      "                   'model': 'resnet18_v1b',\n",
      "                   'ngpus_per_trial': 8,\n",
      "                   'nthreads_per_trial': 128,\n",
      "                   'num_trials': 1,\n",
      "                   'num_workers': 4,\n",
      "                   'problem_type': 'multiclass',\n",
      "                   'search_strategy': 'random',\n",
      "                   'seed': 170,\n",
      "                   'time_limits': 600,\n",
      "                   'wall_clock_tick': 1659563974.724584},\n",
      "  'total_time': 307.2836503982544,\n",
      "  'train_acc': 0.6277472527472527,\n",
      "  'valid_acc': 0.7681159420289855}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 val acc: 0.768\n"
     ]
    }
   ],
   "source": [
    "hyperparameters={'model': model, 'batch_size': batch_size, 'lr': lr, 'epochs': 2}\n",
    "predictor = ImagePredictor()\n",
    "predictor.fit(df_train, time_limit=10*60, hyperparameters=hyperparameters)\n",
    "print('Top-1 val acc: %.3f' % predictor.fit_summary()['valid_acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb78ffe9",
   "metadata": {},
   "source": [
    "<p style=\"padding: 10px; border: 1px solid black;\">\n",
    "<img src=\"./utils/MLU-NEW-logo.png\" alt=\"drawing\" width=\"400\"/> <br/>\n",
    "\n",
    "# Thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a2291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
